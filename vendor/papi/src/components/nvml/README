The PAPI NVML component provides an interface to the NVidia Management
Library (nvml, libnvidia-ml).

In versions 8 and later part of the CUDA Toolkit, The NVIDIA
Management Library is no longer a separate download and is installed
with CUDA. For this reason, we use some of the same environment 
variables as the cuda component. Those instructions are duplicated
here.

BUILD TIME ENVIRONMENT VARIABLES REQUIRED: PAPI_CUDA_ROOT. This is the
CUDA root directory. The default is /opt/cuda. It is seldom correct.
An example that works on ICL's Saturn system (at this writing):

export PAPI_CUDA_ROOT=/usr/local/cuda-10.1

For a standard installed system, this is the only environment variable
required for both compile and runtime. LD_LIBRARY_PATH does not have
to be modified.

On some systems (particularly the ICL Saturn system), environment
variables for CUDA will e preset, or a module load command (e.g.
'module load cuda') will automatically set environment variables like
CUDA_ROOT, CUDA_HOME, or CUDADIR, and modify LD_LIBRARY_PATH to match
this. To avoid conflicts with existing settings, you may wish to (for
example):

export PAPI_CUDA_ROOT=${CUDA_ROOT} 

Using whatever existing environment variable is correct. Typically you
can find such variables by filtering the output of 'env', e.g.

env | grep "cuda" 

to show every environment variable containing 'cuda' in a setting.

Although seldom necessary, it is possible to override other
compile-time directories with environment variables, all starting
with PAPI_.

PAPI_CUDA_INC     default $PAPI_CUDA_ROOT/include
PAPI_NVML_INC     default $PAPI_CUDA_ROOT/include
PAPI_NVML_STUBS   default $PAPI_CUDA_ROOT/lib64/stubs

The "stubs" directory contains dummy libraries for libcuda.so and
libnvidia-ml.so that allows PAPI to be linked on network systems (like
supercomputers) where the compile machine (or head node) may not have
any GPUs installed; and thus no nvidia dynamic libs available, but the
run-target will.  (The component will fail if the first libcuda.so
found on the run-target is the stubs directory.)

RUNTIME LIBRARIES REQUIRED: libcuda.so, libcudart.so, libnvidia-ml.so

RUNTIME ENVIRONMENT VARIABLES: The component allows the standard
library search protocol to be overridden with environment variables.
If it doesn't find the library that way, it will search the "standard
paths"; meaning the directories given by the environment variable
LD_LIBRARY_PATH, followed by the default Linux locations /usr/lib64
and /lib64. The following variables are the optional overrides for
this component, in priority order:

PAPI_NVML_LIBNAME    default "libnvidia-ml.so"
PAPI_NVML_LIBS       default $(PAPI_CUDA_LIBS)
PAPI_CUDA_RTLIBS     default $(PAPI_CUDA_LIBS) 
PAPI_CUDA_LIBS       default $(PAPI_CUDA_ROOT)/lib64
PAPI_CUDA_ROOT       default /opt/cuda

libcuda.so: We use the first found of: 
$(PAPI_CUDA_LIBS)/libcuda.so
$(PAPI_CUDA_ROOT)/lib64/libcuda.so
libcuda.so on the standard paths.

libcudart.so: The RunTime library; we use the first found of:
$(PAPI_CUDA_RTLIBS)/libcudart.so
PAPI_CUDA_ROOT/lib64/libcudart.so
libcudart.so on the standard paths.

libnvidia-ml.so: The nvidia Management Library.
NOTE: libnvidia-ml.so is typically a link to a current version of it,
such as libnvidia-ml.so.418.67. However, on many systems we have
encountered, the link has not been made or points at the /stubs
library, which is not functional. A workaround for that is setting
PAPI_NVML_LIBNAME="libnvidia-ml.so.418.67" (or whatever the current
library name happens to be on your system). The default is
PAPI_NVML_LIBNAME="libnvidia-ml.so".

You can also set PAPI_NVML_LIBS as the correct path to the library, or
do both of these things (force the path, and force the name).

We use the first found of the following:
$(PAPI_NVML_LIBS)/$(PAPI_NVML_LIBNAME) 
$(PAPI_NVML_ROOT)/lib64/$(PAPI_NVML_LIBNAME) 
$(PAPI_CUDA_LIBS)/$(PAPI_NVML_LIBNAME) 
$(PAPI_CUDA_ROOT)/lib64/$(PAPI_NVML_LIBNAME) 
$(PAPI_NVML_LIBNAME) on the standard paths.

LD_LIBRARY_PATH: Instead of specifying the above path environment
variables, it is possible to specify runtime library locations in the
standard path. However, include the existing path as part of the new
path, either in front or at the rear. An example: 

export LD_LIBRARY_PATH=${PAPI_CUDA_ROOT}/lib64:${LD_LIBRARY_PATH}

Configure PAPI with NVML enabled.  
    % cd src
    % ./configure --prefix=some_location --with-components="nvml"

Build with PAPI_CUDA_ROOT specified (ICL's Saturn example again):
    % export PAPI_CUDA_ROOT=/usr/local/cuda-10.1
    % make 

Testing the component requires that libraries for PAPI, CUDA, NVML
can be found or are statically linked in to the executable. The
component libraries cannot be statically linked; only shared object
(.so) libraries can be used.

Note libraries may be found in different places on different systems;
the point is that we need at minimum the environment variable
$PAPI_CUDA_ROOT defined. The underscores and caps are required.

Before starting working with the nvml component, verify it's active by
running:
   % ./papi_component_avail"
and check if it listed under the "Active Components" list.

------------------------------- NOTES -------------------------------
Other download packages may be available at 
https://developer.nvidia.com/gpu-deployment-kit

NVML used to have its own configure step. This is no longer necessary.

At build-time the nVidia compiler, nvcc, needs to be in your path.

Please refer to
http://developer.download.nvidia.com/assets/cuda/files/CUDADownloads/NVML/nvml.pdf
for details about the NVML library.

Power Limiting using NVML (aka power capping) requires root access.

PAPI has added support for power limiting using NVML (on supported
devices from the Kepler family or later).  The executable needs to
have root permissions to change the power limits on the device.

The power_management_limit can be written to set a limit (in
milliWatts) to the power consumption by DEVICE.  The value that can
be written needs to be between the
power_management_limit_constraint_min and
power_management_limit_constraint_max.

nvml:::DEVICE:power_management_limit
nvml:::DEVICE:power_management_limit_constraint_min
nvml:::DEVICE:power_management_limit_constraint_max

A test for writing of the power_management_limit can be found in the
nvml/tests/ directory.
